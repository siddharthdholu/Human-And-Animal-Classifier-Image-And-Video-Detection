{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "531c6ff1",
   "metadata": {},
   "source": [
    "## Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6097ea5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model training takes 35-37 minutes to train.\n",
    "\n",
    "from transformers import CLIPProcessor, CLIPModel\n",
    "from PIL import Image\n",
    "import torch\n",
    "import os\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "model = CLIPModel.from_pretrained(\"openai/clip-vit-base-patch32\").to(device)\n",
    "processor = CLIPProcessor.from_pretrained(\"openai/clip-vit-base-patch32\")\n",
    "\n",
    "def extract_features(image_path):\n",
    "    image = Image.open(image_path).convert(\"RGB\")\n",
    "    inputs = processor(images=image, return_tensors=\"pt\").to(device)\n",
    "    with torch.no_grad():\n",
    "        image_features = model.get_image_features(**inputs)\n",
    "        image_features = image_features / image_features.norm(p=2, dim=-1, keepdim=True)\n",
    "    return image_features.cpu().numpy().flatten()\n",
    "\n",
    "features = []\n",
    "labels = []\n",
    "\n",
    "data_root = \"data\"\n",
    "classes = os.listdir(data_root)\n",
    "\n",
    "for label_idx, class_name in enumerate(classes):\n",
    "    class_dir = os.path.join(data_root, class_name)\n",
    "    for img_name in os.listdir(class_dir):\n",
    "        img_path = os.path.join(class_dir, img_name)\n",
    "        try:\n",
    "            embedding = extract_features(img_path)\n",
    "            features.append(embedding)\n",
    "            labels.append(label_idx)\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing {img_path}: {e}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b82a7bf",
   "metadata": {},
   "source": [
    "## Model Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "033d6949",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classifier Accuracy: 97.72%\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(features, labels, test_size=0.2, random_state=42)\n",
    "\n",
    "clf = LogisticRegression(max_iter=5000)\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "y_pred = clf.predict(X_test)\n",
    "acc = accuracy_score(y_test, y_pred)\n",
    "\n",
    "print(f\"Classifier Accuracy: {acc * 100:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ab5bda2",
   "metadata": {},
   "source": [
    "## Model Exporting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ed35ae1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from joblib import dump\n",
    "\n",
    "dump(clf, 'human_animal_classifier.joblib')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "852291da",
   "metadata": {},
   "source": [
    "## Extracting Classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "4c4708b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Cat', 'Cow', 'Deer', 'Dog', 'Goat', 'Human', 'Sheep']\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "data_root = \"data\"\n",
    "classes = os.listdir(data_root)\n",
    "label_classes = []\n",
    "\n",
    "for label_idx, class_name in enumerate(classes):\n",
    "    label_classes.append(class_name)\n",
    "\n",
    "print(label_classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae2e18a3",
   "metadata": {},
   "source": [
    "## Loading Model and Detecting Classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b98e59f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "from PIL import Image\n",
    "import torch\n",
    "from transformers import CLIPProcessor, CLIPModel\n",
    "from joblib import load\n",
    "\n",
    "clf = load('model/human_animal_classifier.joblib')\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "clip_model = CLIPModel.from_pretrained(\"openai/clip-vit-base-patch32\").to(device)\n",
    "clip_processor = CLIPProcessor.from_pretrained(\"openai/clip-vit-base-patch32\")\n",
    "\n",
    "class_labels = label_classes\n",
    "\n",
    "def extract_features_pil(image):\n",
    "    \"\"\"Extract CLIP features from a PIL image.\"\"\"\n",
    "    inputs = clip_processor(images=image, return_tensors=\"pt\").to(device)\n",
    "    with torch.no_grad():\n",
    "        features = clip_model.get_image_features(**inputs)\n",
    "        features = features / features.norm(p=2, dim=-1, keepdim=True)\n",
    "    return features.cpu().numpy().flatten()\n",
    "\n",
    "def predict_class(features):\n",
    "    \"\"\"Predict class label and confidence using trained classifier.\"\"\"\n",
    "    prob = clf.predict_proba([features])[0]\n",
    "    predicted_idx = prob.argmax()\n",
    "    confidence = prob[predicted_idx]\n",
    "    label = class_labels[predicted_idx]\n",
    "    return label, confidence\n",
    "\n",
    "def detect_from_path(path, is_image=True):\n",
    "    if is_image:\n",
    "        image = Image.open(path).convert(\"RGB\")\n",
    "        features = extract_features_pil(image)\n",
    "        label, confidence = predict_class(features)\n",
    "        print(f\"[IMAGE] Detected: {label} (Confidence: {confidence*100:.2f}%)\")\n",
    "        return label, confidence\n",
    "\n",
    "    else:\n",
    "        cap = cv2.VideoCapture(path)\n",
    "        while cap.isOpened():\n",
    "            ret, frame = cap.read()\n",
    "            if not ret:\n",
    "                break\n",
    "\n",
    "            image = Image.fromarray(cv2.cvtColor(frame, cv2.COLOR_BGR2RGB))\n",
    "            features = extract_features_pil(image)\n",
    "            label, confidence = predict_class(features)\n",
    "\n",
    "            cv2.putText(frame, f\"{label} ({confidence*100:.1f}%)\", (10,30),\n",
    "                        cv2.FONT_HERSHEY_SIMPLEX, 1, (0,255,0), 2)\n",
    "            cv2.imshow('Detection', frame)\n",
    "\n",
    "            if confidence > 0.80:\n",
    "                print(f\"[VIDEO] ALERT: Detected {label} (Confidence: {confidence*100:.2f}%)\")\n",
    "\n",
    "            if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "                break\n",
    "\n",
    "        cap.release()\n",
    "        cv2.destroyAllWindows()\n",
    "        return None, None\n",
    "\n",
    "# === Usage ===\n",
    "# For single image:\n",
    "# detect_from_path(\"test_images/sample.jpg\", is_image=True)\n",
    "\n",
    "# For video:\n",
    "# detect_from_path(\"test_videos/sample_video.mp4\", is_image=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8aa09460",
   "metadata": {},
   "source": [
    "## Detecting From Video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "e2031719",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[VIDEO] ALERT: Detected Human (Confidence: 81.39%)\n",
      "[VIDEO] ALERT: Detected Human (Confidence: 80.68%)\n",
      "[VIDEO] ALERT: Detected Human (Confidence: 80.89%)\n",
      "[VIDEO] ALERT: Detected Human (Confidence: 81.17%)\n",
      "[VIDEO] ALERT: Detected Human (Confidence: 81.09%)\n",
      "[VIDEO] ALERT: Detected Human (Confidence: 80.79%)\n",
      "[VIDEO] ALERT: Detected Human (Confidence: 81.98%)\n",
      "[VIDEO] ALERT: Detected Human (Confidence: 82.46%)\n",
      "[VIDEO] ALERT: Detected Human (Confidence: 83.45%)\n",
      "[VIDEO] ALERT: Detected Human (Confidence: 83.50%)\n",
      "[VIDEO] ALERT: Detected Human (Confidence: 84.36%)\n",
      "[VIDEO] ALERT: Detected Human (Confidence: 85.67%)\n",
      "[VIDEO] ALERT: Detected Human (Confidence: 85.22%)\n",
      "[VIDEO] ALERT: Detected Human (Confidence: 85.61%)\n",
      "[VIDEO] ALERT: Detected Human (Confidence: 85.37%)\n",
      "[VIDEO] ALERT: Detected Human (Confidence: 85.50%)\n",
      "[VIDEO] ALERT: Detected Human (Confidence: 87.47%)\n",
      "[VIDEO] ALERT: Detected Human (Confidence: 86.79%)\n",
      "[VIDEO] ALERT: Detected Human (Confidence: 87.13%)\n",
      "[VIDEO] ALERT: Detected Human (Confidence: 87.73%)\n",
      "[VIDEO] ALERT: Detected Human (Confidence: 88.36%)\n",
      "[VIDEO] ALERT: Detected Human (Confidence: 87.95%)\n",
      "[VIDEO] ALERT: Detected Human (Confidence: 86.57%)\n",
      "[VIDEO] ALERT: Detected Human (Confidence: 85.87%)\n",
      "[VIDEO] ALERT: Detected Human (Confidence: 86.47%)\n",
      "[VIDEO] ALERT: Detected Human (Confidence: 86.02%)\n",
      "[VIDEO] ALERT: Detected Human (Confidence: 85.01%)\n",
      "[VIDEO] ALERT: Detected Human (Confidence: 86.41%)\n",
      "[VIDEO] ALERT: Detected Human (Confidence: 87.21%)\n",
      "[VIDEO] ALERT: Detected Human (Confidence: 87.57%)\n",
      "[VIDEO] ALERT: Detected Human (Confidence: 87.70%)\n",
      "[VIDEO] ALERT: Detected Human (Confidence: 88.98%)\n",
      "[VIDEO] ALERT: Detected Human (Confidence: 87.25%)\n",
      "[VIDEO] ALERT: Detected Human (Confidence: 87.33%)\n",
      "[VIDEO] ALERT: Detected Human (Confidence: 87.67%)\n",
      "[VIDEO] ALERT: Detected Human (Confidence: 88.58%)\n",
      "[VIDEO] ALERT: Detected Human (Confidence: 87.26%)\n",
      "[VIDEO] ALERT: Detected Human (Confidence: 88.36%)\n",
      "[VIDEO] ALERT: Detected Human (Confidence: 89.13%)\n",
      "[VIDEO] ALERT: Detected Human (Confidence: 89.18%)\n",
      "[VIDEO] ALERT: Detected Human (Confidence: 89.11%)\n",
      "[VIDEO] ALERT: Detected Human (Confidence: 89.79%)\n",
      "[VIDEO] ALERT: Detected Human (Confidence: 90.10%)\n",
      "[VIDEO] ALERT: Detected Human (Confidence: 90.06%)\n",
      "[VIDEO] ALERT: Detected Human (Confidence: 90.07%)\n",
      "[VIDEO] ALERT: Detected Human (Confidence: 91.13%)\n",
      "[VIDEO] ALERT: Detected Human (Confidence: 92.16%)\n",
      "[VIDEO] ALERT: Detected Human (Confidence: 91.65%)\n",
      "[VIDEO] ALERT: Detected Human (Confidence: 91.83%)\n",
      "[VIDEO] ALERT: Detected Human (Confidence: 93.36%)\n",
      "[VIDEO] ALERT: Detected Human (Confidence: 93.64%)\n",
      "[VIDEO] ALERT: Detected Human (Confidence: 93.99%)\n",
      "[VIDEO] ALERT: Detected Human (Confidence: 93.63%)\n",
      "[VIDEO] ALERT: Detected Human (Confidence: 93.31%)\n",
      "[VIDEO] ALERT: Detected Human (Confidence: 92.01%)\n",
      "[VIDEO] ALERT: Detected Human (Confidence: 91.59%)\n",
      "[VIDEO] ALERT: Detected Human (Confidence: 92.10%)\n",
      "[VIDEO] ALERT: Detected Human (Confidence: 92.79%)\n",
      "[VIDEO] ALERT: Detected Human (Confidence: 92.93%)\n",
      "[VIDEO] ALERT: Detected Human (Confidence: 93.10%)\n",
      "[VIDEO] ALERT: Detected Human (Confidence: 93.32%)\n",
      "[VIDEO] ALERT: Detected Human (Confidence: 92.60%)\n",
      "[VIDEO] ALERT: Detected Human (Confidence: 93.64%)\n",
      "[VIDEO] ALERT: Detected Human (Confidence: 93.60%)\n",
      "[VIDEO] ALERT: Detected Human (Confidence: 92.89%)\n",
      "[VIDEO] ALERT: Detected Human (Confidence: 93.75%)\n",
      "[VIDEO] ALERT: Detected Human (Confidence: 94.21%)\n",
      "[VIDEO] ALERT: Detected Human (Confidence: 93.62%)\n",
      "[VIDEO] ALERT: Detected Human (Confidence: 92.12%)\n",
      "[VIDEO] ALERT: Detected Human (Confidence: 90.65%)\n",
      "[VIDEO] ALERT: Detected Human (Confidence: 85.07%)\n",
      "[VIDEO] ALERT: Detected Human (Confidence: 86.97%)\n",
      "[VIDEO] ALERT: Detected Human (Confidence: 87.30%)\n",
      "[VIDEO] ALERT: Detected Human (Confidence: 87.49%)\n",
      "[VIDEO] ALERT: Detected Human (Confidence: 87.44%)\n",
      "[VIDEO] ALERT: Detected Human (Confidence: 84.58%)\n",
      "[VIDEO] ALERT: Detected Human (Confidence: 83.52%)\n",
      "[VIDEO] ALERT: Detected Human (Confidence: 82.42%)\n",
      "[VIDEO] ALERT: Detected Human (Confidence: 85.32%)\n",
      "[VIDEO] ALERT: Detected Human (Confidence: 81.48%)\n",
      "[VIDEO] ALERT: Detected Human (Confidence: 82.76%)\n",
      "[VIDEO] ALERT: Detected Human (Confidence: 84.55%)\n",
      "[VIDEO] ALERT: Detected Human (Confidence: 83.91%)\n",
      "[VIDEO] ALERT: Detected Human (Confidence: 82.88%)\n",
      "[VIDEO] ALERT: Detected Human (Confidence: 84.07%)\n",
      "[VIDEO] ALERT: Detected Human (Confidence: 83.71%)\n",
      "[VIDEO] ALERT: Detected Human (Confidence: 82.71%)\n",
      "[VIDEO] ALERT: Detected Human (Confidence: 85.77%)\n",
      "[VIDEO] ALERT: Detected Human (Confidence: 83.07%)\n",
      "[VIDEO] ALERT: Detected Human (Confidence: 80.32%)\n",
      "[VIDEO] ALERT: Detected Human (Confidence: 83.24%)\n",
      "[VIDEO] ALERT: Detected Human (Confidence: 82.77%)\n",
      "[VIDEO] ALERT: Detected Human (Confidence: 82.73%)\n",
      "[VIDEO] ALERT: Detected Human (Confidence: 80.89%)\n",
      "[VIDEO] ALERT: Detected Human (Confidence: 84.16%)\n",
      "[VIDEO] ALERT: Detected Human (Confidence: 81.85%)\n",
      "[VIDEO] ALERT: Detected Human (Confidence: 80.89%)\n",
      "[VIDEO] ALERT: Detected Human (Confidence: 80.09%)\n",
      "[VIDEO] ALERT: Detected Human (Confidence: 81.02%)\n",
      "[VIDEO] ALERT: Detected Human (Confidence: 81.72%)\n",
      "[VIDEO] ALERT: Detected Human (Confidence: 80.41%)\n",
      "[VIDEO] ALERT: Detected Human (Confidence: 83.14%)\n",
      "[VIDEO] ALERT: Detected Human (Confidence: 81.35%)\n",
      "[VIDEO] ALERT: Detected Human (Confidence: 81.51%)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(None, None)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "detect_from_path(\"data_samples\\human.mp4\", is_image=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "6717d7a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[VIDEO] ALERT: Detected Dog (Confidence: 80.50%)\n",
      "[VIDEO] ALERT: Detected Dog (Confidence: 82.74%)\n",
      "[VIDEO] ALERT: Detected Dog (Confidence: 85.58%)\n",
      "[VIDEO] ALERT: Detected Dog (Confidence: 85.25%)\n",
      "[VIDEO] ALERT: Detected Dog (Confidence: 81.58%)\n",
      "[VIDEO] ALERT: Detected Dog (Confidence: 88.46%)\n",
      "[VIDEO] ALERT: Detected Dog (Confidence: 88.74%)\n",
      "[VIDEO] ALERT: Detected Dog (Confidence: 90.55%)\n",
      "[VIDEO] ALERT: Detected Dog (Confidence: 87.03%)\n",
      "[VIDEO] ALERT: Detected Dog (Confidence: 89.02%)\n",
      "[VIDEO] ALERT: Detected Dog (Confidence: 91.11%)\n",
      "[VIDEO] ALERT: Detected Dog (Confidence: 88.66%)\n",
      "[VIDEO] ALERT: Detected Dog (Confidence: 88.25%)\n",
      "[VIDEO] ALERT: Detected Dog (Confidence: 83.07%)\n",
      "[VIDEO] ALERT: Detected Dog (Confidence: 89.22%)\n",
      "[VIDEO] ALERT: Detected Dog (Confidence: 84.67%)\n",
      "[VIDEO] ALERT: Detected Dog (Confidence: 80.17%)\n",
      "[VIDEO] ALERT: Detected Dog (Confidence: 83.53%)\n",
      "[VIDEO] ALERT: Detected Dog (Confidence: 86.48%)\n",
      "[VIDEO] ALERT: Detected Dog (Confidence: 88.50%)\n",
      "[VIDEO] ALERT: Detected Dog (Confidence: 90.90%)\n",
      "[VIDEO] ALERT: Detected Dog (Confidence: 90.18%)\n",
      "[VIDEO] ALERT: Detected Dog (Confidence: 83.75%)\n",
      "[VIDEO] ALERT: Detected Dog (Confidence: 85.24%)\n",
      "[VIDEO] ALERT: Detected Dog (Confidence: 85.47%)\n",
      "[VIDEO] ALERT: Detected Dog (Confidence: 85.05%)\n",
      "[VIDEO] ALERT: Detected Dog (Confidence: 80.84%)\n",
      "[VIDEO] ALERT: Detected Dog (Confidence: 86.53%)\n",
      "[VIDEO] ALERT: Detected Dog (Confidence: 87.18%)\n",
      "[VIDEO] ALERT: Detected Dog (Confidence: 87.14%)\n",
      "[VIDEO] ALERT: Detected Dog (Confidence: 86.74%)\n",
      "[VIDEO] ALERT: Detected Dog (Confidence: 87.62%)\n",
      "[VIDEO] ALERT: Detected Dog (Confidence: 83.74%)\n",
      "[VIDEO] ALERT: Detected Dog (Confidence: 83.33%)\n",
      "[VIDEO] ALERT: Detected Dog (Confidence: 90.15%)\n",
      "[VIDEO] ALERT: Detected Dog (Confidence: 88.09%)\n",
      "[VIDEO] ALERT: Detected Dog (Confidence: 92.54%)\n",
      "[VIDEO] ALERT: Detected Dog (Confidence: 89.85%)\n",
      "[VIDEO] ALERT: Detected Dog (Confidence: 89.27%)\n",
      "[VIDEO] ALERT: Detected Dog (Confidence: 86.10%)\n",
      "[VIDEO] ALERT: Detected Dog (Confidence: 89.94%)\n",
      "[VIDEO] ALERT: Detected Dog (Confidence: 90.72%)\n",
      "[VIDEO] ALERT: Detected Dog (Confidence: 84.88%)\n",
      "[VIDEO] ALERT: Detected Dog (Confidence: 84.46%)\n",
      "[VIDEO] ALERT: Detected Dog (Confidence: 80.14%)\n",
      "[VIDEO] ALERT: Detected Dog (Confidence: 86.23%)\n",
      "[VIDEO] ALERT: Detected Dog (Confidence: 84.96%)\n",
      "[VIDEO] ALERT: Detected Dog (Confidence: 87.58%)\n",
      "[VIDEO] ALERT: Detected Dog (Confidence: 90.96%)\n",
      "[VIDEO] ALERT: Detected Dog (Confidence: 88.15%)\n",
      "[VIDEO] ALERT: Detected Dog (Confidence: 86.78%)\n",
      "[VIDEO] ALERT: Detected Dog (Confidence: 86.14%)\n",
      "[VIDEO] ALERT: Detected Dog (Confidence: 86.16%)\n",
      "[VIDEO] ALERT: Detected Dog (Confidence: 88.35%)\n",
      "[VIDEO] ALERT: Detected Dog (Confidence: 82.34%)\n",
      "[VIDEO] ALERT: Detected Dog (Confidence: 80.90%)\n",
      "[VIDEO] ALERT: Detected Cat (Confidence: 81.80%)\n",
      "[VIDEO] ALERT: Detected Dog (Confidence: 80.72%)\n",
      "[VIDEO] ALERT: Detected Dog (Confidence: 81.89%)\n",
      "[VIDEO] ALERT: Detected Dog (Confidence: 80.11%)\n",
      "[VIDEO] ALERT: Detected Dog (Confidence: 80.34%)\n",
      "[VIDEO] ALERT: Detected Dog (Confidence: 81.23%)\n",
      "[VIDEO] ALERT: Detected Dog (Confidence: 85.73%)\n",
      "[VIDEO] ALERT: Detected Dog (Confidence: 82.90%)\n",
      "[VIDEO] ALERT: Detected Dog (Confidence: 87.78%)\n",
      "[VIDEO] ALERT: Detected Dog (Confidence: 85.72%)\n",
      "[VIDEO] ALERT: Detected Dog (Confidence: 86.24%)\n",
      "[VIDEO] ALERT: Detected Dog (Confidence: 86.20%)\n",
      "[VIDEO] ALERT: Detected Dog (Confidence: 82.94%)\n",
      "[VIDEO] ALERT: Detected Cat (Confidence: 93.05%)\n",
      "[VIDEO] ALERT: Detected Cat (Confidence: 87.33%)\n",
      "[VIDEO] ALERT: Detected Cat (Confidence: 88.39%)\n",
      "[VIDEO] ALERT: Detected Cat (Confidence: 94.35%)\n",
      "[VIDEO] ALERT: Detected Cat (Confidence: 93.99%)\n",
      "[VIDEO] ALERT: Detected Cat (Confidence: 88.15%)\n",
      "[VIDEO] ALERT: Detected Cat (Confidence: 88.40%)\n",
      "[VIDEO] ALERT: Detected Dog (Confidence: 81.95%)\n",
      "[VIDEO] ALERT: Detected Dog (Confidence: 81.61%)\n",
      "[VIDEO] ALERT: Detected Dog (Confidence: 81.46%)\n",
      "[VIDEO] ALERT: Detected Dog (Confidence: 89.40%)\n",
      "[VIDEO] ALERT: Detected Dog (Confidence: 89.93%)\n",
      "[VIDEO] ALERT: Detected Dog (Confidence: 87.03%)\n",
      "[VIDEO] ALERT: Detected Dog (Confidence: 93.03%)\n",
      "[VIDEO] ALERT: Detected Dog (Confidence: 89.00%)\n",
      "[VIDEO] ALERT: Detected Dog (Confidence: 89.25%)\n",
      "[VIDEO] ALERT: Detected Dog (Confidence: 86.69%)\n",
      "[VIDEO] ALERT: Detected Dog (Confidence: 87.78%)\n",
      "[VIDEO] ALERT: Detected Dog (Confidence: 87.03%)\n",
      "[VIDEO] ALERT: Detected Dog (Confidence: 89.16%)\n",
      "[VIDEO] ALERT: Detected Dog (Confidence: 91.14%)\n",
      "[VIDEO] ALERT: Detected Dog (Confidence: 90.47%)\n",
      "[VIDEO] ALERT: Detected Dog (Confidence: 90.69%)\n",
      "[VIDEO] ALERT: Detected Dog (Confidence: 91.05%)\n",
      "[VIDEO] ALERT: Detected Dog (Confidence: 89.03%)\n",
      "[VIDEO] ALERT: Detected Dog (Confidence: 89.95%)\n",
      "[VIDEO] ALERT: Detected Dog (Confidence: 90.00%)\n",
      "[VIDEO] ALERT: Detected Dog (Confidence: 87.80%)\n",
      "[VIDEO] ALERT: Detected Dog (Confidence: 88.48%)\n",
      "[VIDEO] ALERT: Detected Dog (Confidence: 82.66%)\n",
      "[VIDEO] ALERT: Detected Dog (Confidence: 83.32%)\n",
      "[VIDEO] ALERT: Detected Dog (Confidence: 82.12%)\n",
      "[VIDEO] ALERT: Detected Dog (Confidence: 85.10%)\n",
      "[VIDEO] ALERT: Detected Dog (Confidence: 86.61%)\n",
      "[VIDEO] ALERT: Detected Dog (Confidence: 85.04%)\n",
      "[VIDEO] ALERT: Detected Dog (Confidence: 85.62%)\n",
      "[VIDEO] ALERT: Detected Dog (Confidence: 86.99%)\n",
      "[VIDEO] ALERT: Detected Dog (Confidence: 90.22%)\n",
      "[VIDEO] ALERT: Detected Dog (Confidence: 91.60%)\n",
      "[VIDEO] ALERT: Detected Dog (Confidence: 89.33%)\n",
      "[VIDEO] ALERT: Detected Dog (Confidence: 92.76%)\n",
      "[VIDEO] ALERT: Detected Dog (Confidence: 91.55%)\n",
      "[VIDEO] ALERT: Detected Dog (Confidence: 87.08%)\n",
      "[VIDEO] ALERT: Detected Dog (Confidence: 84.68%)\n",
      "[VIDEO] ALERT: Detected Dog (Confidence: 82.75%)\n",
      "[VIDEO] ALERT: Detected Cat (Confidence: 80.07%)\n",
      "[VIDEO] ALERT: Detected Cat (Confidence: 95.30%)\n",
      "[VIDEO] ALERT: Detected Cat (Confidence: 87.72%)\n",
      "[VIDEO] ALERT: Detected Cat (Confidence: 86.75%)\n",
      "[VIDEO] ALERT: Detected Cat (Confidence: 93.05%)\n",
      "[VIDEO] ALERT: Detected Dog (Confidence: 89.79%)\n",
      "[VIDEO] ALERT: Detected Dog (Confidence: 86.45%)\n",
      "[VIDEO] ALERT: Detected Dog (Confidence: 81.47%)\n",
      "[VIDEO] ALERT: Detected Dog (Confidence: 81.11%)\n",
      "[VIDEO] ALERT: Detected Dog (Confidence: 82.98%)\n",
      "[VIDEO] ALERT: Detected Dog (Confidence: 85.27%)\n",
      "[VIDEO] ALERT: Detected Dog (Confidence: 84.90%)\n",
      "[VIDEO] ALERT: Detected Dog (Confidence: 86.72%)\n",
      "[VIDEO] ALERT: Detected Dog (Confidence: 81.66%)\n",
      "[VIDEO] ALERT: Detected Dog (Confidence: 81.18%)\n",
      "[VIDEO] ALERT: Detected Dog (Confidence: 81.72%)\n",
      "[VIDEO] ALERT: Detected Dog (Confidence: 87.59%)\n",
      "[VIDEO] ALERT: Detected Dog (Confidence: 89.66%)\n",
      "[VIDEO] ALERT: Detected Dog (Confidence: 89.05%)\n",
      "[VIDEO] ALERT: Detected Dog (Confidence: 87.67%)\n",
      "[VIDEO] ALERT: Detected Dog (Confidence: 88.55%)\n",
      "[VIDEO] ALERT: Detected Dog (Confidence: 86.95%)\n",
      "[VIDEO] ALERT: Detected Dog (Confidence: 85.49%)\n",
      "[VIDEO] ALERT: Detected Dog (Confidence: 80.67%)\n",
      "[VIDEO] ALERT: Detected Dog (Confidence: 82.73%)\n",
      "[VIDEO] ALERT: Detected Dog (Confidence: 86.35%)\n",
      "[VIDEO] ALERT: Detected Dog (Confidence: 89.20%)\n",
      "[VIDEO] ALERT: Detected Dog (Confidence: 88.18%)\n",
      "[VIDEO] ALERT: Detected Dog (Confidence: 88.49%)\n",
      "[VIDEO] ALERT: Detected Dog (Confidence: 86.26%)\n",
      "[VIDEO] ALERT: Detected Dog (Confidence: 85.16%)\n",
      "[VIDEO] ALERT: Detected Dog (Confidence: 81.30%)\n",
      "[VIDEO] ALERT: Detected Dog (Confidence: 82.82%)\n",
      "[VIDEO] ALERT: Detected Dog (Confidence: 81.04%)\n",
      "[VIDEO] ALERT: Detected Dog (Confidence: 80.93%)\n",
      "[VIDEO] ALERT: Detected Dog (Confidence: 82.13%)\n",
      "[VIDEO] ALERT: Detected Dog (Confidence: 82.32%)\n",
      "[VIDEO] ALERT: Detected Dog (Confidence: 80.86%)\n",
      "[VIDEO] ALERT: Detected Dog (Confidence: 82.65%)\n",
      "[VIDEO] ALERT: Detected Dog (Confidence: 82.45%)\n",
      "[VIDEO] ALERT: Detected Dog (Confidence: 83.24%)\n",
      "[VIDEO] ALERT: Detected Dog (Confidence: 82.66%)\n",
      "[VIDEO] ALERT: Detected Dog (Confidence: 85.79%)\n",
      "[VIDEO] ALERT: Detected Dog (Confidence: 86.78%)\n",
      "[VIDEO] ALERT: Detected Dog (Confidence: 85.09%)\n",
      "[VIDEO] ALERT: Detected Dog (Confidence: 83.55%)\n",
      "[VIDEO] ALERT: Detected Dog (Confidence: 82.04%)\n",
      "[VIDEO] ALERT: Detected Dog (Confidence: 85.16%)\n",
      "[VIDEO] ALERT: Detected Dog (Confidence: 84.86%)\n",
      "[VIDEO] ALERT: Detected Dog (Confidence: 81.59%)\n",
      "[VIDEO] ALERT: Detected Dog (Confidence: 81.89%)\n",
      "[VIDEO] ALERT: Detected Dog (Confidence: 82.22%)\n",
      "[VIDEO] ALERT: Detected Dog (Confidence: 84.20%)\n",
      "[VIDEO] ALERT: Detected Dog (Confidence: 86.61%)\n",
      "[VIDEO] ALERT: Detected Dog (Confidence: 86.23%)\n",
      "[VIDEO] ALERT: Detected Dog (Confidence: 81.75%)\n",
      "[VIDEO] ALERT: Detected Dog (Confidence: 85.20%)\n",
      "[VIDEO] ALERT: Detected Dog (Confidence: 82.33%)\n",
      "[VIDEO] ALERT: Detected Dog (Confidence: 81.34%)\n",
      "[VIDEO] ALERT: Detected Dog (Confidence: 86.59%)\n",
      "[VIDEO] ALERT: Detected Dog (Confidence: 85.76%)\n",
      "[VIDEO] ALERT: Detected Dog (Confidence: 86.04%)\n",
      "[VIDEO] ALERT: Detected Dog (Confidence: 83.77%)\n",
      "[VIDEO] ALERT: Detected Dog (Confidence: 87.61%)\n",
      "[VIDEO] ALERT: Detected Cat (Confidence: 91.99%)\n",
      "[VIDEO] ALERT: Detected Cat (Confidence: 83.75%)\n",
      "[VIDEO] ALERT: Detected Cat (Confidence: 95.43%)\n",
      "[VIDEO] ALERT: Detected Cat (Confidence: 93.00%)\n",
      "[VIDEO] ALERT: Detected Cat (Confidence: 83.44%)\n",
      "[VIDEO] ALERT: Detected Cat (Confidence: 85.27%)\n",
      "[VIDEO] ALERT: Detected Cat (Confidence: 92.55%)\n",
      "[VIDEO] ALERT: Detected Cat (Confidence: 93.87%)\n",
      "[VIDEO] ALERT: Detected Cat (Confidence: 93.50%)\n",
      "[VIDEO] ALERT: Detected Cat (Confidence: 92.61%)\n",
      "[VIDEO] ALERT: Detected Cat (Confidence: 90.55%)\n",
      "[VIDEO] ALERT: Detected Cat (Confidence: 87.34%)\n",
      "[VIDEO] ALERT: Detected Cat (Confidence: 80.30%)\n",
      "[VIDEO] ALERT: Detected Dog (Confidence: 87.42%)\n",
      "[VIDEO] ALERT: Detected Dog (Confidence: 87.65%)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(None, None)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "detect_from_path(\"data_samples\\dog.mp4\", is_image=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40a0c08b",
   "metadata": {},
   "source": [
    "## Detecting From Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "acf355c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[IMAGE] Detected: Human (Confidence: 95.65%)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "('Human', np.float64(0.9564624970180753))"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "detect_from_path(\"data_samples/human.jpg\", is_image=True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "e84e4ac3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[IMAGE] Detected: Deer (Confidence: 99.58%)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "('Deer', np.float64(0.9957980291114441))"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "detect_from_path(\"data_samples/deer.jpg\", is_image=True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "7cddbbc3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[IMAGE] Detected: Cat (Confidence: 97.97%)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "('Cat', np.float64(0.9796721101137771))"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "detect_from_path(\"data_samples/cat.jpg\", is_image=True) "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
